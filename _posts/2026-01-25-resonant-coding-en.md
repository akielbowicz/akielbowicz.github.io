---
layout: default
title: "Resonant Coding: A Method to Master AI Chaos"
lang: en
---
# Resonant Coding: A Method to Master AI Chaos

*This article adapts ideas from Charly's post on Resonant Coding[^charly] and is an adaptation of what was presented in last week's fridAI[^fridai]. It assumes no prior technical knowledge.[^translation]*

*This post is also available in [Spanish](/2026/01/25/resonant-coding.html).*

### The Problem: An Avalanche of Instructions

As a technical lead at Mercado Libre, I faced a particular challenge. We were creating a project from scratch, but the team had few programmers with extensive experience, which required me to review a large part of the work. At the same time, the company pushed us to use Artificial Intelligence (AI) to go faster.

The result was a paradox. We were flooded with an overwhelming amount of "code"—the instructions that make up programs—generated by these AIs. These instructions were often complicated to understand and didn't always meet the necessary quality standards. The review process became a frustrating and slow back-and-forth. Instead of speeding up, we had stalled.

I began to distill the solution to this chaos early in the year, during a vacation, based on the ideas of two experts in the field: Steve Yegge and Dex Horthly[^context-eng]. The core of this method was born from there.

Curiously, the problem seemed to solve itself for a moment. In late October, the quality of the code the team delivered improved drastically. At first, I thought we had achieved something, but the reason was different: one of the AI programming tools we used had received a major update. This reinforced my conviction: we couldn't rely solely on tool improvements; we needed our own robust work process. Coincidentally, the book *Vibe Coding* was released around the same time, which validated many of the ideas I had already been developing.

### Understanding the Beast: How an AI "Thinks"

The main idea of my method is to have a structured process for using AI that is both flexible and simple. To do that, one must first understand how these language models (LMs)[^lm] work.

I summarize them like this:
- They are **text predictors**, like a cell phone's autocomplete, but immensely more advanced.
- They have **no memory**. They don't remember past interactions; they only see the text presented to them at a given moment[^memory].
- Their **attention is limited**. The longer the text we give them, the less efficient they become.
- They are **not predictable**. For the same question, they can give different answers.

To understand the power and limitation of their attention, let's do an exercise. Imagine asking at a dinner party, "What can I cook?". The possible answers are nearly infinite.

Now, add details: "What easy meal can I make for six friends on a Sunday if I have chicken, potatoes, and tomatoes?". The constrained question guides your friends toward a useful answer. The same happens with AIs: the quality of the response directly depends on the quality of the instructions we provide.

The problem is that their limited attention gets "dirty." Think of an analogy: we're camping and have to wash dishes in the river with a single bucket of water.
- For one dish, a bucket is plenty.
- For 10 dishes, the water starts to get murky.
- For 100 dishes, a bucket isn't enough, and the water becomes so dirty that the last dishes end up as bad or worse than before.
- Even worse, if we toss grease into the bucket (irrelevant information), the water becomes unusable.

To leverage the limited attention of AIs, we must be careful with the information we give them and break down large problems into smaller, manageable parts, using a "clean bucket of water" for each one.

### The Method: Research, Planning, and Implementation

To manage this workflow, I propose a three-phase methodology.

#### 1. Research

Given a task, the first step is to use the AI to investigate. We ask it to tell us which parts of the program are important, how they connect, and if there is useful documentation. With that information, we ask it to create a summary. This summary is our first "bucket of water," carefully filled.

But we don't stop there. We subject this summary to a critical review process I call the **"Rule of 5"**[^rule5]:

1.  **Draft:** Create the initial content, aiming for completeness over perfection.
2.  **Correctness:** Is the information correct? Errors and inconsistencies are fixed.
3.  **Clarity:** Is it easy to understand? The language is simplified, and everything is explained clearly.
4.  **Edge Cases:** What could go wrong? Uncommon scenarios are considered.
5.  **Excellence:** Is this the best we can do? We look for ways to optimize or improve the result.

This cycle is repeated until the research summary is solid.

#### 2. Planning

With the research reviewed, we start a new conversation (a new "clean bucket of water"). We give it the summary and ask it to generate a detailed action plan.

Crucially, each task in the plan must be small enough to be performed in a single step. To ensure this, we break the plan into subtasks and describe each with the necessary information. Then, I apply the "Rule of 5" to each of these subtasks.

#### 3. Implementation

With well-defined tasks, the instruction "writing" phase becomes very predictable. The AI executes each small task independently. Its facility for this is enormous: it can modify dozens of files or create validation tests in seconds, something that would take a person hours.

Finally, once everything is done, we again apply the "Rule of 5" to the entire set to ensure everything is well-integrated. This approach of detecting errors as early as possible is something AIs are extremely efficient at[^shift].

### Reusing the Methodology

The great thing about this process is that it's reusable. We can apply the same method to generate the materials that guide us in each step, such as "prompts" or specific templates for a type of problem. For example, Charly uses this idea to create different "visions" of how to implement code, defining his preferences and style. This allows us to leverage methodologies already studied in other professions (from surgery to organizing a World Cup) so that the AI can help us apply them in our own processes.

### Conclusion: Finding Resonance

A poorly worded instruction can generate hundreds of lines of wrong code. A poorly defined plan, tens of thousands. That's why this structured process is vital. The results of each step must be reviewed by people. AIs are good, but the knowledge that only exists in the team's heads must still be contributed by us.

This method allows me to generate much higher quality work than I could do on my own, and in a fraction of the time[^future-work].

The name "Resonant Coding" reminds me of the "Wave Station"[^ondas] I saw in college. If you shake a rope at a specific frequency, the chaos of movement transforms into fixed, harmonic structures. With this method, we do something similar: we adjust the process to find the correct frequency at which our system "vibrates." We stop generating noise and start creating with resonance[^phorma].

---
### Notes

[^lm]: **LM (Large Language Model)**: A type of artificial intelligence program trained to understand and generate text in a way that is very similar to a human.

[^charly]: Charly's original post can be found at [Resonant Coding](https://charly-vibes.github.io/microdancing/en/posts/resonant-coding).

[^memory]: Some tools simulate **memory**, but what they do is add information from the past conversation to the current context to maintain the thread.

[^context-eng]: Dex Horthly's "Context Engineering" ideas can be explored in this document on [Advanced Context Engineering for Coding Agents](https://github.com/humanlayer/advanced-context-engineering-for-coding-agents/blob/main/ace-fca.md).

[^rule5]: The "Rule of 5" is a concept detailed by Steve Yegge. You can read more in his [original documentation](https://github.com/steveyegge/gastown/blob/main/internal/formula/formulas/rule-of-five.formula.toml).

[^shift]: In the software industry, this practice of advancing error detection is known as "shift-left."

[^ondas]: The **Wave Station** is a physics experiment that shows the phenomenon of resonance. A [video demonstration](https://www.youtube.com/watch?v=6zBknO95rB4) from one of the Physics Week exhibitions at UBA can be seen here.

[^fridai]: The **fridAIs** are bi-weekly one-hour meetings held by the team to discuss and share practices and the use of Artificial Intelligence at work.

[^future-work]: The implications of these changes are profound. In a future post, I plan to explore what skills we will need to adapt to the new global work structure, as well as a critical view on who will have access to these tools and the disparity this could generate.

[^phorma]: I apply these same methodologies to scientific research and industry through my venture [phorma scientific](por-que-arme-phorma).

[^translation]: This article was translated from the original Spanish by a large language model from Google.
